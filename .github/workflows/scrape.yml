name: Scrape latest data

on:
  push:
  workflow_dispatch:
  schedule:
    - cron:  '*/5 * * * *'

jobs:
  # Set up
  scrape:
    runs-on: ubuntu-latest
    steps:
    # Step 1
    - name: Check out this repo
      uses: actions/checkout@v2
      with:
        fetch-depth: 0
    # Step 2
    - name: Fetch latest data
      run: |-        
        curl "https://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/all_day.csv" -o usgs_current.csv
    # Step 3
    - name: Install requirements
    # - uses: actions/setup-python@v2
    #  with:
    #    python-version: '3.x'
      run: python -m pip install requests pandas jupyterlab
     
    # Step 4    
    - name: run historical creation script
      run: python create_historical_dataframe.py     
    # Step 5
    - name: Commit and push if it changed
      run: |-
        git config user.name "Automated"
        git config user.email "actions@users.noreply.github.com"
        git add -A
        timestamp=$(date -u)
        git commit -m "Latest data: ${timestamp}" || exit 0
        git push
