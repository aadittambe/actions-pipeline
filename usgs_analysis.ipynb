{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "usgs_analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPEo/xqXoHGjFAO0ONI//CY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aadittambe/actions-pipeline/blob/main/usgs_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "7IgJVp_g8cTc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd # import pandas library for data manipulation and analysis"
      ],
      "metadata": {
        "id": "udZZnQwp8iEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import and clean data from GitHub\n",
        "This code chunk imports the usgs_main.csv from the repo. It then cleans the data by taking the date column and separating it into the following columns: \n",
        "\n",
        "  - date: year-month-day format\n",
        "  - time: the time of the earthquake in 12 hour format \n",
        "  - military_time: the time of the earthquake in 24 hour format\n",
        "\n"
      ],
      "metadata": {
        "id": "SYsgAY0D8kXz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-z2USN5TJYdS"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Read in data\n",
        "df_main = pd.read_csv('https://raw.githubusercontent.com/aadittambe/actions-pipeline/main/usgs_main.csv', index_col=None) # Enter the raw url from your repository\n",
        "\n",
        "# Clean data\n",
        "df_main[\"date_time\"] = pd.to_datetime(df_main[\"time\"]) # Convert time to a column called date_time\n",
        "df_main.drop(\"time\", axis = 1) # Drop the old time column\n",
        "\n",
        "df_main = df_main.assign(   \n",
        "    date = df_main[\"date_time\"].dt.date, # Make new column with date in the format year-month-day\n",
        "    time = df_main[\"date_time\"].dt.strftime('%I:%M %p'), # Make new column with 12 hour format\n",
        "    military_time = df_main[\"date_time\"].dt.time # Make new colum with 24 hour format\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create variables to reference for the analysis sentence\n",
        "This code chunk filters the usg_main.csv csv to calculate:\n",
        "- the number of earthquakes in the dataframe\n",
        "- the earliest earthquake that occured in the dataframe\n",
        "- the latest earthquake that occured in the dataframe \n",
        "- the strongest earthquake that occured in the dataframe  "
      ],
      "metadata": {
        "id": "2OXeqgYxAEQd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Query the dataframe to isolate earthquakes to write about in a sentence\n",
        "number_earthquakes = df_main.shape[0] # Return number of rows of dataframe\n",
        "earliest = df_main[df_main[\"date_time\"] == df_main[\"date_time\"].min()]\n",
        "latest = df_main[df_main[\"date_time\"] == df_main[\"date_time\"].max()]  # Return the row with the earliest earthquake since you started recording\n",
        "strongest = df_main[df_main[\"mag\"] == df_main[\"mag\"].max()] # Return the row with the strongest earthquakes since you started recording"
      ],
      "metadata": {
        "id": "w4MCx-V8Z3VP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Write a dynamically updating analysis sentence\n",
        "\n",
        "This code chunk injects the variables constructed above into an string that updates with the latest variables"
      ],
      "metadata": {
        "id": "8Szl4V2NCHyB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Paste the values into a sentence. If there are earthquakes that happened at the same earliest time or had the same magnitude, we are taking the first row\n",
        "print(f'Since {earliest.iloc[0][\"time\"]} on {earliest.iloc[0][\"date\"].strftime(\"%m/%d/%Y\")} there have been {number_earthquakes} recorded earthquakes. The most recent earthquake was {latest.iloc[0][\"mag\"]} in magnitude and occured in/near {latest.iloc[0][\"place\"]}. The strongest earthquakes since the start of this webscraper was {strongest.iloc[0][\"mag\"]} magnitude and located in/near {strongest.iloc[0][\"place\"]}.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VmqjVs3JmvC",
        "outputId": "0f7d247b-906c-4858-b19d-af114fc8537e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Since 03:31 PM on 03/01/2022 there have been 458 recorded earthquakes. The most recent earthquake was 0.8 in magnitude and occured in/near Southern Alaska. The strongest earthquakes since the start of this webscraper was 6.6 magnitude and located in/near Kermadec Islands, New Zealand.\n"
          ]
        }
      ]
    }
  ]
}